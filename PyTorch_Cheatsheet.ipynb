{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n**Dive into Deep Learning    \n    - ASTON ZHANG, ZACHARY C. LIPTON, MU LI, AND ALEXANDER J. SMOLA**\n","metadata":{}},{"cell_type":"code","source":"import torch\n\n# 1. Basic Tensor Creation and Properties\n\n# Create a 1D tensor with values from 0 to 11 (float32 dtype)\n# torch.arange(start, end, dtype): Creates a 1D tensor with values from start to end-1\n# Output: tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\nx = torch.arange(12, dtype=torch.float32)\nprint(\"x:\", x)\n\n# Get the total number of elements in the tensor\n# tensor.numel(): Returns the total number of elements in the tensor\n# Output: 12\nprint(\"x.numel():\", x.numel())\n\n# Get the shape of the tensor\n# tensor.shape: Returns the dimensions of the tensor\n# Output: torch.Size([12])\nprint(\"x.shape:\", x.shape)\n\n# Reshape the tensor into a 3x4 matrix\n# tensor.reshape(rows, cols): Reshapes the tensor to the specified dimensions\n# Note: -1 can be used for automatic dimension inference\n# Output: tensor([[ 0.,  1.,  2.,  3.],\n#                [ 4.,  5.,  6.,  7.],\n#                [ 8.,  9., 10., 11.]])\nX = x.reshape(3, 4)\nprint(\"X:\", X)\n\n# Create a 2x3x4 tensor filled with zeros\n# torch.zeros(shape): Creates a tensor filled with zeros of specified shape\n# Output: tensor([[[0., 0., 0., 0.],\n#                 [0., 0., 0., 0.],\n#                 [0., 0., 0., 0.]],\n#                [[0., 0., 0., 0.],\n#                 [0., 0., 0., 0.],\n#                 [0., 0., 0., 0.]]])\nprint(\"torch.zeros((2, 3, 4)):\")\nprint(torch.zeros((2, 3, 4)))\n\n# Create a 2x3x4 tensor filled with ones\n# torch.ones(shape): Creates a tensor filled with ones of specified shape\n# Output: tensor([[[1., 1., 1., 1.],\n#                 [1., 1., 1., 1.],\n#                 [1., 1., 1., 1.]],\n#                [[1., 1., 1., 1.],\n#                 [1., 1., 1., 1.],\n#                 [1., 1., 1., 1.]]])\nprint(\"torch.ones((2, 3, 4)):\")\nprint(torch.ones((2, 3, 4)))\n\n# Create a 3x4 tensor with random values from standard normal distribution\n# torch.randn(shape): Creates a tensor with values from N(0,1)\n# Output: Random values, e.g.,\n# tensor([[ 0.1234, -0.5678,  1.2345, -0.9876],\n#         [-0.4321,  0.8765, -0.1234,  0.5678],\n#         [ 1.0987, -0.6543,  0.4321, -0.8765]])\nprint(\"torch.randn(3, 4):\")\nprint(torch.randn(3, 4))\n\n# Create a tensor from a nested list\n# torch.tensor(data): Creates a tensor from provided data\n# Output: tensor([[2, 1, 4, 3],\n#                [1, 2, 3, 4],\n#                [4, 3, 2, 1]])\nprint(\"torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]):\")\nprint(torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]))\n\n# 2. Indexing and Slicing\n\n# Select the last row of X\n# tensor[-1]: Selects the last element along axis 0\n# Output: tensor([ 8.,  9., 10., 11.])\nprint(\"X[-1]:\", X[-1])\n\n# Select rows 1 and 2 (excludes index 3)\n# tensor[start:stop]: Slices tensor from start to stop-1\n# Output: tensor([[ 4.,  5.,  6.,  7.],\n#                [ 8.,  9., 10., 11.]])\nprint(\"X[1:3]:\")\nprint(X[1:3])\n\n# Modify a specific element\n# tensor[row, col] = value: Assigns value to specified position\n# Output: tensor([[ 0.,  1.,  2.,  3.],\n#                [ 4.,  5., 17.,  7.],\n#                [ 8.,  9., 10., 11.]])\nX[1, 2] = 17\nprint(\"X after X[1, 2] = 17:\")\nprint(X)\n\n# Modify first two rows\n# tensor[start:stop, :] = value: Assigns value to selected slice\n# Output: tensor([[12., 12., 12., 12.],\n#                [12., 12., 12., 12.],\n#                [ 8.,  9., 10., 11.]])\nX[:2, :] = 12\nprint(\"X after X[:2, :] = 12:\")\nprint(X)\n\n# 3. Elementwise Operations\n\n# Apply exponential function elementwise\n# torch.exp(tensor): Computes e^x for each element\n# Output: tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969,\n#                162754.7969, 162754.7969, 162754.7969, 162754.7969,\n#                2980.9580, 8103.0840, 22026.4648, 59874.1406])\nprint(\"torch.exp(x):\", torch.exp(x))\n\n# Create new tensors for binary operations\nx = torch.tensor([1.0, 2, 4, 8])\ny = torch.tensor([2, 2, 2, 2])\n\n# Elementwise arithmetic operations\n# tensor + tensor, -, *, /, **: Performs operation elementwise\n# Outputs:\n# x + y: tensor([ 3.,  4.,  6., 10.])\n# x - y: tensor([-1.,  0.,  2.,  6.])\n# x * y: tensor([ 2.,  4.,  8., 16.])\n# x / y: tensor([0.5000, 1.0000, 2.0000, 4.0000])\n# x ** y: tensor([ 1.,  4., 16., 64.])\nprint(\"x + y:\", x + y)\nprint(\"x - y:\", x - y)\nprint(\"x * y:\", x * y)\nprint(\"x / y:\", x / y)\nprint(\"x ** y:\", x ** y)\n\n# 4. Concatenation\n\n# Create tensors for concatenation\nX = torch.arange(12, dtype=torch.float32).reshape((3,4))\nY = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n\n# Concatenate along rows (dim=0)\n# torch.cat((tensors), dim): Concatenates tensors along specified dimension\n# Output: tensor([[ 0.,  1.,  2.,  3.],\n#                [ 4.,  5.,  6.,  7.],\n#                [ 8.,  9., 10., 11.],\n#                [ 2.,  1.,  4.,  3.],\n#                [ 1.,  2.,  3.,  4.],\n#                [ 4.,  3.,  2.,  1.]])\nprint(\"torch.cat((X, Y), dim=0):\")\nprint(torch.cat((X, Y), dim=0))\n\n# Concatenate along columns (dim=1)\n# Output: tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n#                [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n#                [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])\nprint(\"torch.cat((X, Y), dim=1):\")\nprint(torch.cat((X, Y), dim=1))\n\n# 5. Logical Operations\n\n# Elementwise equality comparison\n# tensor == tensor: Returns 1 where elements are equal, 0 otherwise\n# Output: tensor([[False,  True, False,  True],\n#                [False, False, False, False],\n#                [False, False, False, False]])\nprint(\"X == Y:\")\nprint(X == Y)\n\n# Sum all elements\n# tensor.sum(): Returns sum of all elements\n# Output: tensor(66.)\nprint(\"X.sum():\", X.sum())\n\n# 6. Broadcasting\n\n# Create tensors for broadcasting\na = torch.arange(3).reshape((3, 1))\nb = torch.arange(2).reshape((1, 2))\n\n# Display original tensors\n# Outputs:\n# a: tensor([[0],\n#           [1],\n#           [2]])\n# b: tensor([[0, 1]])\nprint(\"a:\", a)\nprint(\"b:\", b)\n\n# Broadcasting addition\n# Expands dimensions to match shapes before addition\n# Output: tensor([[0, 1],\n#                [1, 2],\n#                [2, 3]])\nprint(\"a + b:\")\nprint(a + b)\n\n# 7. Memory Management\n\n# Check if operation creates new memory\nbefore = id(Y)\nY = Y + X\n# id(Y) == before: False (new memory allocated)\nprint(\"id(Y) == before:\", id(Y) == before)\n\n# In-place operation with same memory\nZ = torch.zeros_like(Y)\nprint('id(Z):', id(Z))\nZ[:] = X + Y\nprint('id(Z) after assignment:', id(Z))  # Same id\n\n# In-place addition\nbefore = id(X)\nX += Y\n# id(X) == before: True (same memory)\nprint(\"id(X) == before:\", id(X) == before)\n\n# 8. NumPy Conversion\n\n# Convert tensor to NumPy array and back\nA = X.numpy()\nB = torch.from_numpy(A)\n# type(A): <class 'numpy.ndarray'>\n# type(B): <class 'torch.Tensor'>\nprint(\"type(A):\", type(A))\nprint(\"type(B):\", type(B))\n\n# 9. Scalar Conversion\n\n# Create size-1 tensor and convert to scalar\na = torch.tensor([3.5])\n# Outputs:\n# a: tensor([3.5000])\n# a.item(): 3.5\n# float(a): 3.5\n# int(a): 3\nprint(\"a:\", a)\nprint(\"a.item():\", a.item())\nprint(\"float(a):\", float(a))\nprint(\"int(a):\", int(a))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\n\n# 1. Directory and File Creation\n\n# Create a directory for data storage\n# os.makedirs(path, exist_ok=True): Creates directories recursively\n# - path: Path to create ('../data' - parent directory's data folder)\n# - exist_ok=True: Don't raise error if directory already exists\n# Output: Creates '../data' directory if it doesn't exist (no visible output)\nos.makedirs(os.path.join('..', 'data'), exist_ok=True)\n\n# Define path for CSV file\n# os.path.join(*paths): Joins path components intelligently\n# Output: '../data/house_tiny.csv' (string, stored in data_file)\ndata_file = os.path.join('..', 'data', 'house_tiny.csv')\n\n# Create and write to CSV file\n# open(file, mode) and file.write(): Creates and writes data to file\n# Output: Creates file '../data/house_tiny.csv' with content:\n# NumRooms,RoofType,Price\n# NA,NA,127500\n# 2,NA,106000\n# 4,Slate,178100\n# NA,NA,140000\nwith open(data_file, 'w') as f:\n    f.write('''NumRooms,RoofType,Price\nNA,NA,127500\n2,NA,106000\n4,Slate,178100\nNA,NA,140000''')\n\n# 2. Data Loading and Preprocessing\n\n# Read CSV file into pandas DataFrame\n# pd.read_csv(filepath): Reads CSV file into DataFrame\n# Output:\n#    NumRooms RoofType   Price\n# 0      NaN      NaN  127500\n# 1      2.0      NaN  106000\n# 2      4.0    Slate  178100\n# 3      NaN      NaN  140000\ndata = pd.read_csv(data_file)\nprint(data)\n\n# Split data into inputs (features) and targets\n# data.iloc[rows, cols]: Selects data by integer location\n# - inputs: First two columns (NumRooms, RoofType)\n# - targets: Last column (Price)\ninputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n\n# Convert categorical variables to dummy variables\n# pd.get_dummies(data, dummy_na=True): Creates dummy variables for categorical data\n# - dummy_na=True: Adds column for NA values\n# Output:\n#    NumRooms  RoofType_NA  RoofType_Slate\n# 0      NaN         True           False\n# 1      2.0         True           False\n# 2      4.0        False            True\n# 3      NaN         True           False\ninputs = pd.get_dummies(inputs, dummy_na=True)\nprint(inputs)\n\n# Fill missing values with column means\n# inputs.fillna(value): Replaces NA values with specified value\n# - inputs.mean(): Calculates mean of each column\n# Output:\n#    NumRooms  RoofType_NA  RoofType_Slate\n# 0      3.0         True           False\n# 1      2.0         True           False\n# 2      4.0        False            True\n# 3      3.0         True           False\n# Note: NumRooms mean = (2 + 4)/2 = 3.0\ninputs = inputs.fillna(inputs.mean())\nprint(inputs)\n\n# 3. Convert to PyTorch Tensors\n\n# Convert DataFrames to PyTorch tensors\n# df.to_numpy(dtype): Converts DataFrame to numpy array\n# torch.tensor(data): Creates tensor from numpy array\n# - dtype=float: Ensures float data type\n# Outputs:\n# X: tensor([[3., 1., 0.],\n#           [2., 1., 0.],\n#           [4., 0., 1.],\n#           [3., 1., 0.]], dtype=torch.float64)\n# y: tensor([127500., 106000., 178100., 140000.], dtype=torch.float64)\nX = torch.tensor(inputs.to_numpy(dtype=float))\ny = torch.tensor(targets.to_numpy(dtype=float))\nprint(\"X:\", X)\nprint(\"y:\", y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# 1. Basic Tensor Operations\n\n# Create scalar tensors and perform basic arithmetic\n# torch.tensor(data): Creates a tensor from data\n# Basic arithmetic operations (+, *, /, **): Elementwise operations\n# Outputs:\n# x + y: tensor(5.)\n# x * y: tensor(6.)\n# x / y: tensor(1.5)\n# x ** y: tensor(9.)\nx = torch.tensor(3.0)\ny = torch.tensor(2.0)\nprint(\"x + y:\", x + y)\nprint(\"x * y:\", x * y)\nprint(\"x / y:\", x / y)\nprint(\"x ** y:\", x ** y)\n\n# 2. Vector Operations\n\n# Create and manipulate a 1D tensor\n# torch.arange(n): Creates tensor with values from 0 to n-1\n# tensor[index]: Accesses element at index\n# len(tensor): Returns length of tensor (first dimension)\n# Outputs:\n# x: tensor([0, 1, 2])\n# x[2]: tensor(2)\n# len(x): 3\nx = torch.arange(3)\nprint(\"x:\", x)\nprint(\"x[2]:\", x[2])\nprint(\"len(x):\", len(x))\n\n# 3. Matrix Operations\n\n# Create and transpose a matrix\n# torch.arange(n).reshape(rows, cols): Creates and reshapes tensor\n# tensor.T: Returns transpose of matrix\n# Output:\n# A.T: tensor([[0, 2, 4],\n#             [1, 3, 5]])\nA = torch.arange(6).reshape(3, 2)\nprint(\"A.T:\", A.T)\n\n# Create matrices and perform operations\n# tensor.clone(): Creates a copy with new memory\n# Outputs:\n# A: tensor([[0., 1., 2.],\n#           [3., 4., 5.]])\n# A + B: tensor([[ 0.,  2.,  4.],\n#               [ 6.,  8., 10.]])\n# A * B: tensor([[ 0.,  1.,  4.],\n#               [ 9., 16., 25.]])\nA = torch.arange(6, dtype=torch.float32).reshape(2, 3)\nB = A.clone()\nprint(\"A:\", A)\nprint(\"A + B:\", A + B)\nprint(\"A * B:\", A * B)\n\n# 4. Broadcasting with Scalar\n\n# Broadcasting with scalar operations\n# Scalar operations automatically broadcast to tensor shape\n# Outputs:\n# a + X: tensor([[[ 2,  3,  4,  5],\n#                 [ 6,  7,  8,  9],\n#                 [10, 11, 12, 13]],\n#                [[14, 15, 16, 17],\n#                 [18, 19, 20, 21],\n#                 [22, 23, 24, 25]]])\n# (a * X).shape: torch.Size([2, 3, 4])\na = 2\nX = torch.arange(24).reshape(2, 3, 4)\nprint(\"a + X:\", a + X)\nprint(\"(a * X).shape:\", (a * X).shape)\n\n# 5. Reduction Operations\n\n# Sum operations\n# tensor.sum(): Sums all elements\n# Outputs:\n# x: tensor([0., 1., 2.])\n# x.sum(): tensor(3.)\nx = torch.arange(3, dtype=torch.float32)\nprint(\"x:\", x)\nprint(\"x.sum():\", x.sum())\n\n# Sum along specific axes\n# tensor.sum(axis=n): Sums along specified axis\n# Outputs:\n# A.shape: torch.Size([2, 3])\n# A.sum(axis=0).shape: torch.Size([3])\n# A.shape: torch.Size([2, 3])\n# A.sum(axis=1).shape: torch.Size([2])\nprint(\"A.shape:\", A.shape)\nprint(\"A.sum(axis=0).shape:\", A.sum(axis=0).shape)\nprint(\"A.shape:\", A.shape)\nprint(\"A.sum(axis=1).shape:\", A.sum(axis=1).shape)\n\n# Mean calculations\n# tensor.mean(): Computes mean of all elements\n# tensor.numel(): Returns total number of elements\n# Outputs:\n# A.mean(): tensor(2.5)\n# A.sum() / A.numel(): tensor(2.5)\n# A.mean(axis=0): tensor([1.5, 2.5, 3.5])\n# A.sum(axis=0) / A.shape[0]: tensor([1.5, 2.5, 3.5])\nprint(\"A.mean():\", A.mean())\nprint(\"A.sum() / A.numel():\", A.sum() / A.numel())\nprint(\"A.mean(axis=0):\", A.mean(axis=0))\nprint(\"A.sum(axis=0) / A.shape[0]:\", A.sum(axis=0) / A.shape[0])\n\n# Sum with dimension preservation\n# tensor.sum(axis=n, keepdims=True): Preserves dimensions\n# Outputs:\n# sum_A: tensor([[ 3.],\n#               [12.]])\n# sum_A.shape: torch.Size([2, 1])\n# A / sum_A: tensor([[0.0000, 0.3333, 0.6667],\n#                   [0.2500, 0.3333, 0.4167]])\nsum_A = A.sum(axis=1, keepdims=True)\nprint(\"sum_A:\", sum_A)\nprint(\"sum_A.shape:\", sum_A.shape)\nprint(\"A / sum_A:\", A / sum_A)\n\n# Cumulative sum\n# tensor.cumsum(axis=n): Computes cumulative sum along axis\n# Output:\n# tensor([[0., 1., 2.],\n#         [3., 5., 7.]])\nprint(\"A.cumsum(axis=0):\", A.cumsum(axis=0))\n\n# 6. Vector and Matrix Products\n\n# Dot product and matrix-vector product\n# torch.dot(x, y): Computes dot product of vectors\n# torch.mv(A, x): Matrix-vector product\n# A @ x: Matrix-vector product (operator notation)\n# Outputs:\n# x: tensor([0., 1., 2.])\n# y: tensor([1., 1., 1.])\n# torch.dot(x, y): tensor(3.)\n# torch.sum(x * y): tensor(3.)\ny = torch.ones(3, dtype=torch.float32)\nprint(\"x:\", x)\nprint(\"y:\", y)\nprint(\"torch.dot(x, y):\", torch.dot(x, y))\nprint(\"torch.sum(x * y):\", torch.sum(x * y))\n\n# Matrix-matrix product\n# torch.mm(A, B): Matrix multiplication\n# A @ B: Matrix multiplication (operator notation)\n# Outputs:\n# A.shape: torch.Size([2, 3])\n# x.shape: torch.Size([3])\n# torch.mv(A, x): tensor([ 5., 14.])\n# A @ x: tensor([ 5., 14.])\n# B: tensor([[1., 1., 1., 1.],\n#           [1., 1., 1., 1.],\n#           [1., 1., 1., 1.]])\n# torch.mm(A, B): tensor([[ 3.,  3.,  3.,  3.],\n#                         [12., 12., 12., 12.]])\n# A @ B: tensor([[ 3.,  3.,  3.,  3.],\n#               [12., 12., 12., 12.]])\nprint(\"A.shape:\", A.shape)\nprint(\"x.shape:\", x.shape)\nprint(\"torch.mv(A, x):\", torch.mv(A, x))\nprint(\"A @ x:\", A @ x)\nB = torch.ones(3, 4)\nprint(\"torch.mm(A, B):\", torch.mm(A, B))\nprint(\"A @ B:\", A @ B)\n\n# 7. Norms\n\n# Vector and matrix norms\n# torch.norm(tensor): Computes L2 norm\n# torch.abs(tensor).sum(): Computes L1 norm\n# Outputs:\n# torch.norm(u): tensor(5.)  # sqrt(3^2 + (-4)^2) = 5\n# torch.abs(u).sum(): tensor(7.)  # |3| + |-4| = 7\n# torch.norm(torch.ones((4, 9))): tensor(6.)  # sqrt(36) = 6\nu = torch.tensor([3.0, -4.0])\nprint(\"torch.norm(u):\", torch.norm(u))\nprint(\"torch.abs(u).sum():\", torch.abs(u).sum())\nprint(\"torch.norm(torch.ones((4, 9))):\", torch.norm(torch.ones((4, 9))))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}